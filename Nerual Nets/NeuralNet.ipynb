{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.130608</td>\n",
       "      <td>20.313166</td>\n",
       "      <td>50.098630</td>\n",
       "      <td>53.819004</td>\n",
       "      <td>68.302515</td>\n",
       "      <td>1439.486661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.051670</td>\n",
       "      <td>10.007557</td>\n",
       "      <td>9.681779</td>\n",
       "      <td>10.006835</td>\n",
       "      <td>10.083092</td>\n",
       "      <td>159.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.873000</td>\n",
       "      <td>-10.122000</td>\n",
       "      <td>14.165000</td>\n",
       "      <td>18.628000</td>\n",
       "      <td>28.221000</td>\n",
       "      <td>966.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.393575</td>\n",
       "      <td>13.415250</td>\n",
       "      <td>43.316000</td>\n",
       "      <td>47.015750</td>\n",
       "      <td>61.542000</td>\n",
       "      <td>1329.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.053500</td>\n",
       "      <td>20.574000</td>\n",
       "      <td>50.306500</td>\n",
       "      <td>53.925500</td>\n",
       "      <td>68.344500</td>\n",
       "      <td>1426.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.928250</td>\n",
       "      <td>26.741000</td>\n",
       "      <td>56.979250</td>\n",
       "      <td>60.477000</td>\n",
       "      <td>74.930750</td>\n",
       "      <td>1540.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.836000</td>\n",
       "      <td>57.969000</td>\n",
       "      <td>80.023000</td>\n",
       "      <td>89.961000</td>\n",
       "      <td>104.710000</td>\n",
       "      <td>2138.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2           x3           x4           x5  \\\n",
       "count  2300.000000  2300.000000  2300.000000  2300.000000  2300.000000   \n",
       "mean      9.130608    20.313166    50.098630    53.819004    68.302515   \n",
       "std      10.051670    10.007557     9.681779    10.006835    10.083092   \n",
       "min     -30.873000   -10.122000    14.165000    18.628000    28.221000   \n",
       "25%       2.393575    13.415250    43.316000    47.015750    61.542000   \n",
       "50%       9.053500    20.574000    50.306500    53.925500    68.344500   \n",
       "75%      15.928250    26.741000    56.979250    60.477000    74.930750   \n",
       "max      40.836000    57.969000    80.023000    89.961000   104.710000   \n",
       "\n",
       "                 y  \n",
       "count  2300.000000  \n",
       "mean   1439.486661  \n",
       "std     159.969037  \n",
       "min     966.910000  \n",
       "25%    1329.600000  \n",
       "50%    1426.700000  \n",
       "75%    1540.150000  \n",
       "max    2138.200000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/whu24.csv', names= ['x1', 'x2', 'x3', 'x4','x5', 'y'])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['x1', 'x2', 'x3', 'x4','x5']]\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.027309</td>\n",
       "      <td>20.258701</td>\n",
       "      <td>50.144458</td>\n",
       "      <td>53.800349</td>\n",
       "      <td>68.214058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.122487</td>\n",
       "      <td>10.029083</td>\n",
       "      <td>9.699734</td>\n",
       "      <td>9.938293</td>\n",
       "      <td>10.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.873000</td>\n",
       "      <td>-10.122000</td>\n",
       "      <td>14.165000</td>\n",
       "      <td>18.628000</td>\n",
       "      <td>28.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.280400</td>\n",
       "      <td>13.411250</td>\n",
       "      <td>43.380250</td>\n",
       "      <td>47.065000</td>\n",
       "      <td>61.484250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.006800</td>\n",
       "      <td>20.552000</td>\n",
       "      <td>50.354500</td>\n",
       "      <td>53.920000</td>\n",
       "      <td>68.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.828500</td>\n",
       "      <td>26.691250</td>\n",
       "      <td>57.017250</td>\n",
       "      <td>60.351500</td>\n",
       "      <td>74.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.836000</td>\n",
       "      <td>57.969000</td>\n",
       "      <td>80.023000</td>\n",
       "      <td>89.961000</td>\n",
       "      <td>104.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2           x3           x4           x5\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000\n",
       "mean      9.027309    20.258701    50.144458    53.800349    68.214058\n",
       "std      10.122487    10.029083     9.699734     9.938293    10.015642\n",
       "min     -30.873000   -10.122000    14.165000    18.628000    28.221000\n",
       "25%       2.280400    13.411250    43.380250    47.065000    61.484250\n",
       "50%       9.006800    20.552000    50.354500    53.920000    68.290500\n",
       "75%      15.828500    26.691250    57.017250    60.351500    74.764000\n",
       "max      40.836000    57.969000    80.023000    89.961000   104.710000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.819267</td>\n",
       "      <td>20.676267</td>\n",
       "      <td>49.793113</td>\n",
       "      <td>53.943373</td>\n",
       "      <td>68.892227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.553811</td>\n",
       "      <td>9.871697</td>\n",
       "      <td>9.571632</td>\n",
       "      <td>10.468692</td>\n",
       "      <td>10.520026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-16.954000</td>\n",
       "      <td>-3.793400</td>\n",
       "      <td>20.370000</td>\n",
       "      <td>26.082000</td>\n",
       "      <td>40.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.719225</td>\n",
       "      <td>13.475250</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>46.871250</td>\n",
       "      <td>62.144750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.565100</td>\n",
       "      <td>20.667500</td>\n",
       "      <td>49.860500</td>\n",
       "      <td>54.185500</td>\n",
       "      <td>69.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.534750</td>\n",
       "      <td>27.330750</td>\n",
       "      <td>56.809500</td>\n",
       "      <td>61.170500</td>\n",
       "      <td>75.618250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.158000</td>\n",
       "      <td>52.949000</td>\n",
       "      <td>76.563000</td>\n",
       "      <td>78.909000</td>\n",
       "      <td>94.622000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1          x2          x3          x4          x5\n",
       "count  300.000000  300.000000  300.000000  300.000000  300.000000\n",
       "mean     9.819267   20.676267   49.793113   53.943373   68.892227\n",
       "std      9.553811    9.871697    9.571632   10.468692   10.520026\n",
       "min    -16.954000   -3.793400   20.370000   26.082000   40.287000\n",
       "25%      2.719225   13.475250   43.020000   46.871250   62.144750\n",
       "50%      9.565100   20.667500   49.860500   54.185500   69.050500\n",
       "75%     16.534750   27.330750   56.809500   61.170500   75.618250\n",
       "max     35.158000   52.949000   76.563000   78.909000   94.622000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5184 candidates, totalling 15552 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1987s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1491s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2197s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.9459s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 310 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1956s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1238s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0212s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (10.9330s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 435 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1887s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1147s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.6258s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Done 533 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (14.2370s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1789s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 629 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1396s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2759s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (9.7388s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 722 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 757 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1890s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1455s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 803 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0323s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.4623s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 897 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 930 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1902s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1678s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 1003 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3591s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.1891s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1068 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1899s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1600s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 1105 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0385s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.3949s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1219 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1256 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1860s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1251s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3201s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Done 1348 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.0093s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1888s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1355s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0437s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.5848s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1538 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1579 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1959s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1595s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4890s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.5882s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1694 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1745 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1969s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1291s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2688s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.7854s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1866 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1981s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1930 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0890s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 2015 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2062 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1916s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1500s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1052s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8911s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 2187 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1820s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 2239 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1255s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2613s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.1852s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 2388 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1978s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1646s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0935s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.9294s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 2520 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1808s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1354s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 2575 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1796s.) Setting batch_size=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.6480s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 2693 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1843s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1469s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 2791 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1977s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.6846s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 2876 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1939s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1407s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2030s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.9964s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 3013 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1942s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1187s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 3103 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0217s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.1916s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1874s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 3221 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1511s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0709s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.3675s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 3351 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1909s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1442s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0847s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.2453s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 3490 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1897s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1484s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 3567 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2155s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.2423s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 3688 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1825s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1394s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5036s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.2908s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 3825 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1894s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1235s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4023s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.4051s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 3992 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1854s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1548s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2210s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.4583s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 4138 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1810s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1350s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 4249 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2658s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.3860s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1916s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1170s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 4356 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0213s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.8253s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1873s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1545s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 4548 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0007s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.5810s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 4669 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1814s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1287s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2515s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.1063s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1957s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1620s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 4836 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1511s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8525s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1807s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1464s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2632s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8054s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 5134 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1788s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1479s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3125s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.8003s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 5283 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1997s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1940s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1484s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.1170s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 5425 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1841s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1223s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 5508 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1874s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.0115s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1861s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1462s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 5711 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1605s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.4500s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1949s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1560s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 5842 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0390s.) Setting batch_size=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too slow (10.3302s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1900s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 5974 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1279s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5486s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.3374s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 6144 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1848s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1123s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1725s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.0181s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1922s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 6302 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1246s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3555s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.6314s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 6474 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1880s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0545s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 6587 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1885s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1507s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0769s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.6656s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 6742 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1855s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1256s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4122s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (15.0898s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 6928 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1995s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1517s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1547s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (9.2248s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 7089 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1888s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1627s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3160s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (10.1757s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1886s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 7258 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1714s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3659s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.7850s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1854s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1335s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 7429 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0637s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8021s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1872s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1482s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 7598 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2753s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8629s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1899s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1441s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 7776 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0495s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.6213s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1977s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1428s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 7937 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0590s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.4136s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1998s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1409s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 8113 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2858s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.7533s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1950s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1284s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 8296 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.6351s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.5158s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1965s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1142s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4089s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.4065s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 8541 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1845s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1743s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3217s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (5.6859s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 8708 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1896s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1376s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2313s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.5835s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 8869 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1889s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1886s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0188s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.9339s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 9036 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1870s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1183s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3558s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.4613s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1936s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 9223 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1515s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2680s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.7568s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1983s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1327s.) Setting batch_size=6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0159s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Done 9453 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.8618s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1792s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1157s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3765s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.7852s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 9664 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1898s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1548s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2486s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.5619s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 9831 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1813s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0469s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 9971 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1883s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1509s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3744s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.7721s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 10156 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1818s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1335s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0472s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.9598s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 10330 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1891s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1977s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2044s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.8367s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 10501 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1854s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1573s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1161s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.8432s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1994s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 10673 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1374s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3526s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.1394s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1998s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1367s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1122s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 10897 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.5665s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1975s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1348s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2034s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.6976s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 11101 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1904s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1283s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1519s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (14.4263s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 11306 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1910s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1551s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1502s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8554s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1932s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 11485 tasks      | elapsed: 30.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1216s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4847s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.2401s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1944s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1814s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1268s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.9013s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 11764 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1890s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1345s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1794s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (9.0431s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 11951 tasks      | elapsed: 31.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1950s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1593s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1732s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.6524s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1844s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1160s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 12138 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3021s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (12.6649s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1847s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1571s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2058s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.5389s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 12423 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1892s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1449s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4119s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.7584s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1966s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1293s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 12628 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1005s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.3389s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1859s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1711s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1895s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.8987s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 12912 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1850s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1859s.) Setting batch_size=4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2619s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.7810s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1959s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1627s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 13101 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4600s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.4970s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1924s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1432s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0301s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.3631s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 13349 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1865s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1986s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3022s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2115s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 13541 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1994s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1258s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3098s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.0902s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1960s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1166s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 13757 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2483s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (17.8158s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1837s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1221s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5051s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.2543s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 14054 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1911s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1341s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2737s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (8.5009s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1869s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1144s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 14288 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4844s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (13.4936s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1911s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1874s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0961s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.6845s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 14539 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1920s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1403s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.4633s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (9.1446s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1890s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1665s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 14761 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0706s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (11.4127s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1906s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1298s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2164s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (14.1635s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 15026 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1915s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1404s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0517s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (9.8966s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1969s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 15229 tasks      | elapsed: 40.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1054s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1933s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1780s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 15410 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2973s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (10.1035s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1805s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1526s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 15552 out of 15552 | elapsed: 41.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': array([ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]), 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'momentum': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_oneLayer_tune = MLPRegressor(activation = 'identity',\n",
    "                                max_iter = 500,\n",
    "                                solver = 'adam',\n",
    "                                learning_rate = 'constant',\n",
    "                                early_stopping = True,\n",
    "                                random_state=42\n",
    "                                )\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': np.arange(8,24),\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7),\n",
    "    'momentum': np.arange(0.1, 1, 0.1), \n",
    "}\n",
    "clf_oneLayer = GridSearchCV(nn_oneLayer_tune, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_oneLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8258316639310699\n",
      "Best params: {'alpha': 1e-06, 'hidden_layer_sizes': 18, 'learning_rate_init': 0.01, 'momentum': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "score.append(clf_oneLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_oneLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_oneLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2106.332077459347\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "layers = []\n",
    "nn_oneLayer = MLPRegressor(\n",
    "                hidden_layer_sizes= clf_oneLayer.best_params_['hidden_layer_sizes'],\n",
    "                activation = 'identity',\n",
    "                max_iter = 500,\n",
    "                solver='adam',\n",
    "                alpha= clf_oneLayer.best_params_['alpha'],\n",
    "                learning_rate_init= clf_oneLayer.best_params_['learning_rate_init'],\n",
    "                learning_rate= 'constant',\n",
    "                early_stopping = True,\n",
    "                momentum= clf_oneLayer.best_params_['momentum'],\n",
    "                random_state = 42\n",
    "                ).fit(X_train, y_train)\n",
    "layers.append(clf_oneLayer.best_params_['hidden_layer_sizes'])\n",
    "loss.append(nn_oneLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_oneLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 22 candidates, totalling 66 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    6.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-06, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 3), (18, 4), (18, 5), (18, 6), (18, 7), (18, 8), (18, 9), (18, 10), (18, 11), (18, 12), (18, 13), (18, 14), (18, 15), (18, 16), (18, 17), (18, 18), (18, 19), (18, 20), (18, 21), (18, 22), (18, 23), (18, 24)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the second layer\n",
    "nn_twoLayer_tune = MLPRegressor(activation = 'identity',\n",
    "                                max_iter = 500,\n",
    "                                solver='adam',\n",
    "                                alpha= 1e-06,\n",
    "                                learning_rate_init= 0.01,\n",
    "                                learning_rate='constant',\n",
    "                                early_stopping = True,\n",
    "                                momentum= 0.1,\n",
    "                                random_state = 42\n",
    "                               )\n",
    "parameters = {'hidden_layer_sizes': [ (18,i) for i in np.arange(3,25)] }\n",
    "clf_twoLayer = GridSearchCV(nn_twoLayer_tune, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_twoLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.825675286813624\n",
      "Best params: {'hidden_layer_sizes': (18, 13)}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_twoLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_twoLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_twoLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2198.006733954523\n"
     ]
    }
   ],
   "source": [
    "nn_twoLayer = MLPRegressor( hidden_layer_sizes= (18,13),\n",
    "                            activation = 'identity',\n",
    "                            max_iter = 500,\n",
    "                            solver='adam',\n",
    "                            alpha=1e-06,\n",
    "                            learning_rate_init=0.01,\n",
    "                            learning_rate='constant',\n",
    "                            early_stopping = True,\n",
    "                            momentum=0.1,\n",
    "                            random_state = 42\n",
    "                           ).fit(X_train, y_train)\n",
    "layers.append(tuple(clf_twoLayer.best_params_['hidden_layer_sizes']))\n",
    "loss.append(nn_twoLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_twoLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0968s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3666s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.7527s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 221 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1983s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 324 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 367 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0232s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 409 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 461 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 517 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 577 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 641 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1983s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2619s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 747 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 782 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1960s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 823 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0171s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 892 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 931 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(18, 13), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'momentum': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_twoLayer_check = MLPRegressor(hidden_layer_sizes= (18,13),\n",
    "                  solver='adam',\n",
    "                  activation = 'identity',\n",
    "                  max_iter = 500,\n",
    "                  learning_rate='constant',\n",
    "                  early_stopping = True,\n",
    "                  random_state=42\n",
    "                 )\n",
    "parameters = {\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7),\n",
    "    'momentum': np.arange(0.1, 1, 0.1), \n",
    "}\n",
    "clf_twoLayer_check = GridSearchCV(nn_twoLayer_check, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_twoLayer_check.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.825675286813624\n",
      "Best params: {'alpha': 1e-06, 'learning_rate_init': 0.01, 'momentum': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(clf_twoLayer_check.best_score_))\n",
    "print(\"Best params: {}\".format(clf_twoLayer_check.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 22 candidates, totalling 66 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1706s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-06, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 3), (18, 13, 4), (18, 13, 5), (18, 13, 6), (18, 13, 7), (18, 13, 8), (18, 13, 9), (18, 13, 10), (18, 13, 11), (18, 13, 12), (18, 13, 13), (18, 13, 14), (18, 13, 15), (18, 13, 16), (18, 13, 17), (18, 13, 18), (18, 13, 19), (18, 13, 20), (18, 13, 21), (18, 13, 22), (18, 13, 23), (18, 13, 24)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the third layer\n",
    "nn_threeLayer = MLPRegressor( activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init=0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum=0.1,\n",
    "                              random_state = 42\n",
    "                            )\n",
    "parameters = {'hidden_layer_sizes': [(18,13,i) for i in np.arange(3,25)] }\n",
    "clf_threeLayer = GridSearchCV(nn_threeLayer, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_threeLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8261740473142789\n",
      "Best params: {'hidden_layer_sizes': (18, 13, 22)}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_threeLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_threeLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_threeLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2271.9685273000005\n"
     ]
    }
   ],
   "source": [
    "nn_threeLayer = MLPRegressor(hidden_layer_sizes = clf_threeLayer.best_params_['hidden_layer_sizes'],\n",
    "                             activation = 'identity',\n",
    "                             max_iter = 500,\n",
    "                             solver='adam',\n",
    "                             alpha=1e-06,\n",
    "                             learning_rate_init=0.01,\n",
    "                             learning_rate='constant',\n",
    "                             early_stopping = True,\n",
    "                             momentum=0.1,\n",
    "                             random_state = 42\n",
    "                            ).fit(X_train, y_train)\n",
    "loss.append(nn_threeLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_threeLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5508 candidates, totalling 16524 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3437 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3605 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3690 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3777 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3953 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4224 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4317 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4410 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4505 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4697 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4794 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5093 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5194 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5297 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5505 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5610 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5717 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5933 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6153 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6264 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6377 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6490 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6605 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6720 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6954 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7073 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7313 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7434 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7557 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7680 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7805 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8057 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8184 tasks      | elapsed: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8313 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8573 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8704 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8837 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8970 tasks      | elapsed: 37.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 9105 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9240 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9377 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9514 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9653 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9933 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10074 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10217 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10505 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10650 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=-1)]: Done 10797 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10944 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=-1)]: Done 11093 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11393 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11544 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11697 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11850 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12005 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12160 tasks      | elapsed: 50.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12317 tasks      | elapsed: 51.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12474 tasks      | elapsed: 52.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12633 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 53.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12953 tasks      | elapsed: 54.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13277 tasks      | elapsed: 55.4min\n",
      "[Parallel(n_jobs=-1)]: Done 13440 tasks      | elapsed: 56.1min\n",
      "[Parallel(n_jobs=-1)]: Done 13605 tasks      | elapsed: 56.8min\n",
      "[Parallel(n_jobs=-1)]: Done 13770 tasks      | elapsed: 57.5min\n",
      "[Parallel(n_jobs=-1)]: Done 13937 tasks      | elapsed: 58.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14104 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=-1)]: Done 14273 tasks      | elapsed: 59.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 60.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14613 tasks      | elapsed: 60.9min\n",
      "[Parallel(n_jobs=-1)]: Done 14784 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14957 tasks      | elapsed: 62.2min\n",
      "[Parallel(n_jobs=-1)]: Done 15130 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=-1)]: Done 15305 tasks      | elapsed: 63.6min\n",
      "[Parallel(n_jobs=-1)]: Done 15480 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15657 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 15834 tasks      | elapsed: 66.1min\n",
      "[Parallel(n_jobs=-1)]: Done 16013 tasks      | elapsed: 66.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 67.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16373 tasks      | elapsed: 68.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16524 out of 16524 | elapsed: 69.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 6), (18, 13, 7), (18, 13, 8), (18, 13, 9), (18, 13, 10), (18, 13, 11), (18, 13, 12), (18, 13, 13), (18, 13, 14), (18, 13, 15), (18, 13, 16), (18, 13, 17), (18, 13, 18), (18, 13, 19), (18, 13, 20), (18, 13, 21), (18, 13, 22)], 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'momentum': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_threeLayer_check = MLPRegressor(\n",
    "                  solver='adam',\n",
    "                  activation = 'identity',\n",
    "                  max_iter = 500,\n",
    "                  learning_rate='constant',\n",
    "                  early_stopping = True,\n",
    "                  random_state=42\n",
    "                 )\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(18,13,i) for i in np.arange(6,23)],\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7),\n",
    "    'momentum': np.arange(0.1, 1, 0.1), \n",
    "}\n",
    "clf_threeLayer_check = GridSearchCV(nn_threeLayer_check, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_threeLayer_check.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8261740483616352\n",
      "Best params: {'alpha': 0.1, 'hidden_layer_sizes': (18, 13, 22), 'learning_rate_init': 0.01, 'momentum': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(clf_threeLayer_check.best_score_))\n",
    "print(\"Best params: {}\".format(clf_threeLayer_check.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:    2.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-06, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 22, 8), (18, 13, 22, 9), (18, 13, 22, 10), (18, 13, 22, 11), (18, 13, 22, 12), (18, 13, 22, 13), (18, 13, 22, 14), (18, 13, 22, 15), (18, 13, 22, 16), (18, 13, 22, 17), (18, 13, 22, 18), (18, 13, 22, 19), (18, 13, 22, 20), (18, 13, 22, 21), (18, 13, 22, 22)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the fourth layer\n",
    "nn_fourLayer = MLPRegressor( activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init=0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum=0.1,\n",
    "                              random_state = 42\n",
    "                            )\n",
    "parameters = {'hidden_layer_sizes': [(18,13,22,i) for i in range(8,23)] }\n",
    "clf_fourLayer = GridSearchCV(nn_fourLayer, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_fourLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.824979636517304\n",
      "Best params: {'hidden_layer_sizes': (18, 13, 22, 13)}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_fourLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_fourLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_fourLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2182.7027173701817\n"
     ]
    }
   ],
   "source": [
    "# Tunning the fourth layer\n",
    "nn_fourLayer = MLPRegressor(  hidden_layer_sizes= (18, 13, 22, 13),\n",
    "                              activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init= 0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum= 0.1,\n",
    "                              random_state = 42\n",
    "                            ).fit(X_train, y_train)\n",
    "loss.append(nn_fourLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_fourLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:    5.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-06, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 22, 13, 8), (18, 13, 22, 13, 9), (18, 13, 22, 13, 10), (18, 13, 22, 13, 11), (18, 13, 22, 13, 12), (18, 13, 22, 13, 13), (18, 13, 22, 13, 14), (18, 13, 22, 13, 15), (18, 13, 22, 13, 16), (18, 13, 22, 13, 17), (18, 13, 22, 13, 18), (18, 13, 22, 13, 19), (18, 13, 22, 13, 20), (18, 13, 22, 13, 21), (18, 13, 22, 13, 22)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the fifth layer\n",
    "nn_fiveLayer = MLPRegressor( activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init=0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum=0.1,\n",
    "                              random_state = 42\n",
    "                            )\n",
    "parameters = {'hidden_layer_sizes': [(18,13,22,13,i) for i in range(8,23)] }\n",
    "clf_fiveLayer = GridSearchCV(nn_fiveLayer, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_fiveLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8254553372913099\n",
      "Best params: {'hidden_layer_sizes': (18, 13, 22, 13, 14)}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_fiveLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_fiveLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_fiveLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2106.8443472095087\n"
     ]
    }
   ],
   "source": [
    "# Tunning the fifth layer\n",
    "nn_fiveLayer = MLPRegressor(  hidden_layer_sizes= (18, 13, 22, 13, 14),\n",
    "                              activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init= 0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum= 0.1,\n",
    "                              random_state = 42\n",
    "                            ).fit(X_train, y_train)\n",
    "loss.append(nn_fiveLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_fiveLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:    3.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-06, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 22, 13, 14, 8), (18, 13, 22, 13, 14, 9), (18, 13, 22, 13, 14, 10), (18, 13, 22, 13, 14, 11), (18, 13, 22, 13, 14, 12), (18, 13, 22, 13, 14, 13), (18, 13, 22, 13, 14, 14), (18, 13, 22, 13, 14, 15), (18, 13, 22, 13, 14, 16), (18, 13, 22, 13, 14, 17), (18, 13, 22, 13, 14, 18), (18, 13, 22, 13, 14, 19), (18, 13, 22, 13, 14, 20), (18, 13, 22, 13, 14, 21), (18, 13, 22, 13, 14, 22)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the sixth layer\n",
    "nn_sixLayer = MLPRegressor( activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init=0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum=0.1,\n",
    "                              random_state = 42\n",
    "                            )\n",
    "parameters = {'hidden_layer_sizes': [(18,13,22,13, 14, i) for i in range(8,23)] }\n",
    "clf_sixLayer = GridSearchCV(nn_sixLayer, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_sixLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.82573071524411\n",
      "Best params: {'hidden_layer_sizes': (18, 13, 22, 13, 14, 13)}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_sixLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_sixLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_sixLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2184.701308846609\n"
     ]
    }
   ],
   "source": [
    "# Tunning the sixth layer\n",
    "nn_sixLayer = MLPRegressor(  hidden_layer_sizes= (18, 13, 22, 13, 14, 13),\n",
    "                              activation = 'identity',\n",
    "                              max_iter = 500,\n",
    "                              solver='adam',\n",
    "                              alpha= 1e-06,\n",
    "                              learning_rate_init= 0.01,\n",
    "                              learning_rate='constant',\n",
    "                              early_stopping = True,\n",
    "                              momentum= 0.1,\n",
    "                              random_state = 42\n",
    "                            ).fit(X_train, y_train)\n",
    "loss.append(nn_sixLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_sixLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: [2106.332077459347, 2198.006733954523, 2271.9685273000005, 2182.7027173701817, 2106.8443472095087, 2184.701308846609, 2106.8443472095087]\n",
      "Test loss: [2747.737983208486, 2753.098704853684, 2707.3927804068253, 2695.8690869531197, 2926.5224152880846, 2800.598067699733]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_loss = []\n",
    "y_predict = nn_oneLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_twoLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_threeLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_fourLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_fiveLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_sixLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "print(\"Train loss: {}\".format(loss))\n",
    "print(\"Test loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,len(loss)+1),loss, marker='o', color='orange', linewidth=2, label= 'train loss')\n",
    "plt.plot(np.arange(1,len(loss)+1),test_loss, marker='o', color='blue', linewidth=2, label= 'test loss')\n",
    "plt.xlabel('Number of layers')\n",
    "plt.ylabel('Mean Squared Error(MSE)')\n",
    "plt.title('Training data vs Testing data')\n",
    "plt.axvline(x=4, linestyle='--', color='red')\n",
    "plt.savefig('Training data vs Testing data.png')            \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
