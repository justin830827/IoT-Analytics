{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.130608</td>\n",
       "      <td>20.313166</td>\n",
       "      <td>50.098630</td>\n",
       "      <td>53.819004</td>\n",
       "      <td>68.302515</td>\n",
       "      <td>1439.486661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.051670</td>\n",
       "      <td>10.007557</td>\n",
       "      <td>9.681779</td>\n",
       "      <td>10.006835</td>\n",
       "      <td>10.083092</td>\n",
       "      <td>159.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.873000</td>\n",
       "      <td>-10.122000</td>\n",
       "      <td>14.165000</td>\n",
       "      <td>18.628000</td>\n",
       "      <td>28.221000</td>\n",
       "      <td>966.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.393575</td>\n",
       "      <td>13.415250</td>\n",
       "      <td>43.316000</td>\n",
       "      <td>47.015750</td>\n",
       "      <td>61.542000</td>\n",
       "      <td>1329.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.053500</td>\n",
       "      <td>20.574000</td>\n",
       "      <td>50.306500</td>\n",
       "      <td>53.925500</td>\n",
       "      <td>68.344500</td>\n",
       "      <td>1426.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.928250</td>\n",
       "      <td>26.741000</td>\n",
       "      <td>56.979250</td>\n",
       "      <td>60.477000</td>\n",
       "      <td>74.930750</td>\n",
       "      <td>1540.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.836000</td>\n",
       "      <td>57.969000</td>\n",
       "      <td>80.023000</td>\n",
       "      <td>89.961000</td>\n",
       "      <td>104.710000</td>\n",
       "      <td>2138.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2           x3           x4           x5  \\\n",
       "count  2300.000000  2300.000000  2300.000000  2300.000000  2300.000000   \n",
       "mean      9.130608    20.313166    50.098630    53.819004    68.302515   \n",
       "std      10.051670    10.007557     9.681779    10.006835    10.083092   \n",
       "min     -30.873000   -10.122000    14.165000    18.628000    28.221000   \n",
       "25%       2.393575    13.415250    43.316000    47.015750    61.542000   \n",
       "50%       9.053500    20.574000    50.306500    53.925500    68.344500   \n",
       "75%      15.928250    26.741000    56.979250    60.477000    74.930750   \n",
       "max      40.836000    57.969000    80.023000    89.961000   104.710000   \n",
       "\n",
       "                 y  \n",
       "count  2300.000000  \n",
       "mean   1439.486661  \n",
       "std     159.969037  \n",
       "min     966.910000  \n",
       "25%    1329.600000  \n",
       "50%    1426.700000  \n",
       "75%    1540.150000  \n",
       "max    2138.200000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/whu24.csv', names= ['x1', 'x2', 'x3', 'x4','x5', 'y'])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['x1', 'x2', 'x3', 'x4','x5']]\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.027309</td>\n",
       "      <td>20.258701</td>\n",
       "      <td>50.144458</td>\n",
       "      <td>53.800349</td>\n",
       "      <td>68.214058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.122487</td>\n",
       "      <td>10.029083</td>\n",
       "      <td>9.699734</td>\n",
       "      <td>9.938293</td>\n",
       "      <td>10.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.873000</td>\n",
       "      <td>-10.122000</td>\n",
       "      <td>14.165000</td>\n",
       "      <td>18.628000</td>\n",
       "      <td>28.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.280400</td>\n",
       "      <td>13.411250</td>\n",
       "      <td>43.380250</td>\n",
       "      <td>47.065000</td>\n",
       "      <td>61.484250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.006800</td>\n",
       "      <td>20.552000</td>\n",
       "      <td>50.354500</td>\n",
       "      <td>53.920000</td>\n",
       "      <td>68.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.828500</td>\n",
       "      <td>26.691250</td>\n",
       "      <td>57.017250</td>\n",
       "      <td>60.351500</td>\n",
       "      <td>74.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.836000</td>\n",
       "      <td>57.969000</td>\n",
       "      <td>80.023000</td>\n",
       "      <td>89.961000</td>\n",
       "      <td>104.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2           x3           x4           x5\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000\n",
       "mean      9.027309    20.258701    50.144458    53.800349    68.214058\n",
       "std      10.122487    10.029083     9.699734     9.938293    10.015642\n",
       "min     -30.873000   -10.122000    14.165000    18.628000    28.221000\n",
       "25%       2.280400    13.411250    43.380250    47.065000    61.484250\n",
       "50%       9.006800    20.552000    50.354500    53.920000    68.290500\n",
       "75%      15.828500    26.691250    57.017250    60.351500    74.764000\n",
       "max      40.836000    57.969000    80.023000    89.961000   104.710000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.819267</td>\n",
       "      <td>20.676267</td>\n",
       "      <td>49.793113</td>\n",
       "      <td>53.943373</td>\n",
       "      <td>68.892227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.553811</td>\n",
       "      <td>9.871697</td>\n",
       "      <td>9.571632</td>\n",
       "      <td>10.468692</td>\n",
       "      <td>10.520026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-16.954000</td>\n",
       "      <td>-3.793400</td>\n",
       "      <td>20.370000</td>\n",
       "      <td>26.082000</td>\n",
       "      <td>40.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.719225</td>\n",
       "      <td>13.475250</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>46.871250</td>\n",
       "      <td>62.144750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.565100</td>\n",
       "      <td>20.667500</td>\n",
       "      <td>49.860500</td>\n",
       "      <td>54.185500</td>\n",
       "      <td>69.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.534750</td>\n",
       "      <td>27.330750</td>\n",
       "      <td>56.809500</td>\n",
       "      <td>61.170500</td>\n",
       "      <td>75.618250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.158000</td>\n",
       "      <td>52.949000</td>\n",
       "      <td>76.563000</td>\n",
       "      <td>78.909000</td>\n",
       "      <td>94.622000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1          x2          x3          x4          x5\n",
       "count  300.000000  300.000000  300.000000  300.000000  300.000000\n",
       "mean     9.819267   20.676267   49.793113   53.943373   68.892227\n",
       "std      9.553811    9.871697    9.571632   10.468692   10.520026\n",
       "min    -16.954000   -3.793400   20.370000   26.082000   40.287000\n",
       "25%      2.719225   13.475250   43.020000   46.871250   62.144750\n",
       "50%      9.565100   20.667500   49.860500   54.185500   69.050500\n",
       "75%     16.534750   27.330750   56.809500   61.170500   75.618250\n",
       "max     35.158000   52.949000   76.563000   78.909000   94.622000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': array([18, 19, 20, 21, 22, 23, 24, 25]), 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_oneLayer_tune = MLPRegressor(activation = 'logistic',\n",
    "                                max_iter = 500,\n",
    "                                solver = 'adam',\n",
    "                                learning_rate = 'constant',\n",
    "                                early_stopping = True,\n",
    "                                random_state=42\n",
    "                                )\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': np.arange(18,26),\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7), \n",
    "}\n",
    "clf_oneLayer = GridSearchCV(nn_oneLayer_tune, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_oneLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8630777870595906\n",
      "Best params: {'alpha': 0.1, 'hidden_layer_sizes': 21, 'learning_rate_init': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "score.append(clf_oneLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_oneLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_oneLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 888.9365247543599\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "layers = []\n",
    "nn_oneLayer = MLPRegressor(\n",
    "                hidden_layer_sizes= clf_oneLayer.best_params_['hidden_layer_sizes'],\n",
    "                activation = 'logistic',\n",
    "                max_iter = 500,\n",
    "                solver='adam',\n",
    "                alpha= clf_oneLayer.best_params_['alpha'],\n",
    "                learning_rate_init= clf_oneLayer.best_params_['learning_rate_init'],\n",
    "                learning_rate= 'constant',\n",
    "                early_stopping = True,\n",
    "                random_state = 42\n",
    "                ).fit(X_train, y_train)\n",
    "layers.append(clf_oneLayer.best_params_['hidden_layer_sizes'])\n",
    "loss.append(nn_oneLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_oneLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed: 11.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(21, 12), (21, 13), (21, 14), (21, 15), (21, 16), (21, 17), (21, 18), (21, 19), (21, 20), (21, 21), (21, 22), (21, 23)], 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the second layer\n",
    "nn_twoLayer_tune = MLPRegressor(activation = 'logistic',\n",
    "                                max_iter = 500,\n",
    "                                solver='adam',\n",
    "                                learning_rate='constant',\n",
    "                                early_stopping = True,\n",
    "                                random_state = 42\n",
    "                               )\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [ (21,i) for i in np.arange(12,24)],\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7), \n",
    "}\n",
    "clf_twoLayer = GridSearchCV(nn_twoLayer_tune, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_twoLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9409307668174363\n",
      "Best params: {'alpha': 0.0001, 'hidden_layer_sizes': (21, 20), 'learning_rate_init': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_twoLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_twoLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_twoLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 232.1343410560544\n"
     ]
    }
   ],
   "source": [
    "nn_twoLayer = MLPRegressor(hidden_layer_sizes= clf_twoLayer.best_params_['hidden_layer_sizes'],\n",
    "                            activation = 'logistic',\n",
    "                            max_iter = 500,\n",
    "                            solver='adam',\n",
    "                            alpha= clf_twoLayer.best_params_['alpha'],\n",
    "                            learning_rate_init= clf_twoLayer.best_params_['learning_rate_init'],\n",
    "                            learning_rate= 'constant',\n",
    "                            early_stopping = True,\n",
    "                            random_state = 42\n",
    "                        ).fit(X_train, y_train) \n",
    "\n",
    "layers.append(clf_twoLayer.best_params_['hidden_layer_sizes'])\n",
    "loss.append(nn_twoLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_twoLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(21, 20, 13), (21, 20, 14), (21, 20, 15), (21, 20, 16), (21, 20, 17), (21, 20, 18), (21, 20, 19), (21, 20, 20), (21, 20, 21)], 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the third layer\n",
    "nn_threeLayer = MLPRegressor(\n",
    "                            activation = 'logistic',\n",
    "                            max_iter = 500,\n",
    "                            solver='adam',\n",
    "                            learning_rate='constant',\n",
    "                            early_stopping = True,\n",
    "                            random_state = 42\n",
    "                            )\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [ (21,20,i) for i in np.arange(13,22)],\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7), \n",
    "}\n",
    "clf_threeLayer = GridSearchCV(nn_threeLayer, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_threeLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.15959943737900834\n",
      "Best params: {'alpha': 0.1, 'hidden_layer_sizes': (21, 20, 18), 'learning_rate_init': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_threeLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_threeLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_threeLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 124.16405197579618\n"
     ]
    }
   ],
   "source": [
    "nn_threeLayer = MLPRegressor(hidden_layer_sizes= clf_threeLayer.best_params_['hidden_layer_sizes'],\n",
    "                            activation = 'logistic',\n",
    "                            max_iter = 500,\n",
    "                            solver='adam',\n",
    "                            alpha= clf_threeLayer.best_params_['alpha'],\n",
    "                            learning_rate_init= clf_threeLayer.best_params_['learning_rate_init'],\n",
    "                            learning_rate= 'constant',\n",
    "                            early_stopping = True,\n",
    "                            random_state = 42\n",
    "                        ).fit(X_train, y_train) \n",
    "loss.append(nn_threeLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_threeLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed: 11.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(21, 20, 18, 12), (21, 20, 18, 13), (21, 20, 18, 14), (21, 20, 18, 15), (21, 20, 18, 16), (21, 20, 18, 17), (21, 20, 18, 18), (21, 20, 18, 19)], 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tunning the fourth layer\n",
    "nn_fourLayer = MLPRegressor( activation = 'logistic',\n",
    "                            max_iter = 500,\n",
    "                            solver='adam',\n",
    "                            learning_rate='constant',\n",
    "                            early_stopping = True,\n",
    "                            random_state = 42\n",
    "                            )\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(21,20,18,i) for i in range(12,20)],\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7), \n",
    "}\n",
    "clf_fourLayer = GridSearchCV(nn_fourLayer, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_fourLayer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.0017981275850611595\n",
      "Best params: {'alpha': 1e-06, 'hidden_layer_sizes': (21, 20, 18, 14), 'learning_rate_init': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score.append(clf_fourLayer.best_score_)\n",
    "print(\"Best score: {}\".format(clf_fourLayer.best_score_))\n",
    "print(\"Best params: {}\".format(clf_fourLayer.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 12259.020420123194\n"
     ]
    }
   ],
   "source": [
    "# Tunning the fourth layer\n",
    "nn_fourLayer = MLPRegressor(  hidden_layer_sizes= clf_fourLayer.best_params_['hidden_layer_sizes'],\n",
    "                            activation = 'logistic',\n",
    "                            max_iter = 500,\n",
    "                            solver='adam',\n",
    "                            alpha= clf_fourLayer.best_params_['alpha'],\n",
    "                            learning_rate_init= clf_fourLayer.best_params_['learning_rate_init'],\n",
    "                            learning_rate= 'constant',\n",
    "                            early_stopping = True,\n",
    "                            random_state = 42\n",
    "                        ).fit(X_train, y_train)\n",
    "loss.append(nn_fourLayer.loss_)\n",
    "print(\"loss: {}\".format(nn_fourLayer.loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: [888.9365247543599, 232.1343410560544, 124.16405197579618, 12259.020420123194]\n",
      "Test loss: [1512.314076156989, 595.5819847000959, 259.1956470266515, 27830.579025432988]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_loss = []\n",
    "y_predict = nn_oneLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_twoLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_threeLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "y_predict = nn_fourLayer.predict(X_test)\n",
    "test_loss.append(mean_squared_error(y_test, y_predict))\n",
    "print(\"Train loss: {}\".format(loss))\n",
    "print(\"Test loss: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,len(loss)+1),loss, marker='o', color='orange', linewidth=2, label= 'train loss')\n",
    "plt.plot(np.arange(1,len(loss)+1),test_loss, marker='o', color='blue', linewidth=2, label= 'test loss')\n",
    "plt.xlabel('Number of layers')\n",
    "plt.ylabel('Mean Squared Error(MSE)')\n",
    "plt.title('Training data vs Testing data')\n",
    "# plt.axvline(x=4, linestyle='--', color='red')\n",
    "plt.savefig('Training data vs Testing data.png')            \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.998\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.998\n",
      "Method:                 Least Squares   F-statistic:                          2.333e+05\n",
      "Date:                Wed, 20 Nov 2019   Prob (F-statistic):                        0.00\n",
      "Time:                        14:20:51   Log-Likelihood:                         -12835.\n",
      "No. Observations:                2300   AIC:                                  2.568e+04\n",
      "Df Residuals:                    2295   BIC:                                  2.571e+04\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             7.9736      0.133     60.042      0.000       7.713       8.234\n",
      "x2             3.4508      0.131     26.270      0.000       3.193       3.708\n",
      "x3             6.1477      0.118     51.899      0.000       5.915       6.380\n",
      "x4             6.3730      0.112     56.895      0.000       6.153       6.593\n",
      "x5             9.4455      0.099     95.281      0.000       9.251       9.640\n",
      "==============================================================================\n",
      "Omnibus:                     1463.625   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18255.249\n",
      "Skew:                           2.856   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.565   Cond. No.                         10.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regression model\n",
    "import statsmodels.api as sm\n",
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y,X).fit()\n",
    "print (model.summary())\n",
    "y_predict_regess = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ANN model\n",
    "y_predict_ann = nn_threeLayer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSE(y_true, y_predict):\n",
    "    y_true = y_true.to_numpy()\n",
    "    if len(y_true) != len(y_predict):\n",
    "        return\n",
    "    sse = 0\n",
    "    for i in range(len(y_true)):\n",
    "        sse += (y_true[i] - y_predict[i]) ** 2\n",
    "    return sse\n",
    "\n",
    "ann_sse = SSE(y_test,y_predict_ann)\n",
    "regress_sse = SSE(y_test,y_predict_regess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN's SSE: 77758.6941079954\n",
      "Best Regression's SSE: 633402884.1532137\n"
     ]
    }
   ],
   "source": [
    "print (\"Best ANN's SSE: {}\".format(ann_sse))\n",
    "print (\"Best Regression's SSE: {}\".format(regress_sse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
