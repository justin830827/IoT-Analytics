{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.130608</td>\n",
       "      <td>20.313166</td>\n",
       "      <td>50.098630</td>\n",
       "      <td>53.819004</td>\n",
       "      <td>68.302515</td>\n",
       "      <td>1439.486661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.051670</td>\n",
       "      <td>10.007557</td>\n",
       "      <td>9.681779</td>\n",
       "      <td>10.006835</td>\n",
       "      <td>10.083092</td>\n",
       "      <td>159.969037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.873000</td>\n",
       "      <td>-10.122000</td>\n",
       "      <td>14.165000</td>\n",
       "      <td>18.628000</td>\n",
       "      <td>28.221000</td>\n",
       "      <td>966.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.393575</td>\n",
       "      <td>13.415250</td>\n",
       "      <td>43.316000</td>\n",
       "      <td>47.015750</td>\n",
       "      <td>61.542000</td>\n",
       "      <td>1329.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.053500</td>\n",
       "      <td>20.574000</td>\n",
       "      <td>50.306500</td>\n",
       "      <td>53.925500</td>\n",
       "      <td>68.344500</td>\n",
       "      <td>1426.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.928250</td>\n",
       "      <td>26.741000</td>\n",
       "      <td>56.979250</td>\n",
       "      <td>60.477000</td>\n",
       "      <td>74.930750</td>\n",
       "      <td>1540.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.836000</td>\n",
       "      <td>57.969000</td>\n",
       "      <td>80.023000</td>\n",
       "      <td>89.961000</td>\n",
       "      <td>104.710000</td>\n",
       "      <td>2138.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2           x3           x4           x5  \\\n",
       "count  2300.000000  2300.000000  2300.000000  2300.000000  2300.000000   \n",
       "mean      9.130608    20.313166    50.098630    53.819004    68.302515   \n",
       "std      10.051670    10.007557     9.681779    10.006835    10.083092   \n",
       "min     -30.873000   -10.122000    14.165000    18.628000    28.221000   \n",
       "25%       2.393575    13.415250    43.316000    47.015750    61.542000   \n",
       "50%       9.053500    20.574000    50.306500    53.925500    68.344500   \n",
       "75%      15.928250    26.741000    56.979250    60.477000    74.930750   \n",
       "max      40.836000    57.969000    80.023000    89.961000   104.710000   \n",
       "\n",
       "                 y  \n",
       "count  2300.000000  \n",
       "mean   1439.486661  \n",
       "std     159.969037  \n",
       "min     966.910000  \n",
       "25%    1329.600000  \n",
       "50%    1426.700000  \n",
       "75%    1540.150000  \n",
       "max    2138.200000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/whu24.csv', names= ['x1', 'x2', 'x3', 'x4','x5', 'y'])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['x1', 'x2', 'x3', 'x4','x5']]\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.027309</td>\n",
       "      <td>20.258701</td>\n",
       "      <td>50.144458</td>\n",
       "      <td>53.800349</td>\n",
       "      <td>68.214058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.122487</td>\n",
       "      <td>10.029083</td>\n",
       "      <td>9.699734</td>\n",
       "      <td>9.938293</td>\n",
       "      <td>10.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.873000</td>\n",
       "      <td>-10.122000</td>\n",
       "      <td>14.165000</td>\n",
       "      <td>18.628000</td>\n",
       "      <td>28.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.280400</td>\n",
       "      <td>13.411250</td>\n",
       "      <td>43.380250</td>\n",
       "      <td>47.065000</td>\n",
       "      <td>61.484250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.006800</td>\n",
       "      <td>20.552000</td>\n",
       "      <td>50.354500</td>\n",
       "      <td>53.920000</td>\n",
       "      <td>68.290500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.828500</td>\n",
       "      <td>26.691250</td>\n",
       "      <td>57.017250</td>\n",
       "      <td>60.351500</td>\n",
       "      <td>74.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.836000</td>\n",
       "      <td>57.969000</td>\n",
       "      <td>80.023000</td>\n",
       "      <td>89.961000</td>\n",
       "      <td>104.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x1           x2           x3           x4           x5\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000\n",
       "mean      9.027309    20.258701    50.144458    53.800349    68.214058\n",
       "std      10.122487    10.029083     9.699734     9.938293    10.015642\n",
       "min     -30.873000   -10.122000    14.165000    18.628000    28.221000\n",
       "25%       2.280400    13.411250    43.380250    47.065000    61.484250\n",
       "50%       9.006800    20.552000    50.354500    53.920000    68.290500\n",
       "75%      15.828500    26.691250    57.017250    60.351500    74.764000\n",
       "max      40.836000    57.969000    80.023000    89.961000   104.710000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.819267</td>\n",
       "      <td>20.676267</td>\n",
       "      <td>49.793113</td>\n",
       "      <td>53.943373</td>\n",
       "      <td>68.892227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.553811</td>\n",
       "      <td>9.871697</td>\n",
       "      <td>9.571632</td>\n",
       "      <td>10.468692</td>\n",
       "      <td>10.520026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-16.954000</td>\n",
       "      <td>-3.793400</td>\n",
       "      <td>20.370000</td>\n",
       "      <td>26.082000</td>\n",
       "      <td>40.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.719225</td>\n",
       "      <td>13.475250</td>\n",
       "      <td>43.020000</td>\n",
       "      <td>46.871250</td>\n",
       "      <td>62.144750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.565100</td>\n",
       "      <td>20.667500</td>\n",
       "      <td>49.860500</td>\n",
       "      <td>54.185500</td>\n",
       "      <td>69.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.534750</td>\n",
       "      <td>27.330750</td>\n",
       "      <td>56.809500</td>\n",
       "      <td>61.170500</td>\n",
       "      <td>75.618250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.158000</td>\n",
       "      <td>52.949000</td>\n",
       "      <td>76.563000</td>\n",
       "      <td>78.909000</td>\n",
       "      <td>94.622000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1          x2          x3          x4          x5\n",
       "count  300.000000  300.000000  300.000000  300.000000  300.000000\n",
       "mean     9.819267   20.676267   49.793113   53.943373   68.892227\n",
       "std      9.553811    9.871697    9.571632   10.468692   10.520026\n",
       "min    -16.954000   -3.793400   20.370000   26.082000   40.287000\n",
       "25%      2.719225   13.475250   43.020000   46.871250   62.144750\n",
       "50%      9.565100   20.667500   49.860500   54.185500   69.050500\n",
       "75%     16.534750   27.330750   56.809500   61.170500   75.618250\n",
       "max     35.158000   52.949000   76.563000   78.909000   94.622000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1436s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2637s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1967s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1443s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5469s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2508s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1915s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1232s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 342 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.7899s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (11.5864s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 427 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1989s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1118s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done 515 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.6638s.) Setting batch_size=3.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (11.5842s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 594 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1812s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1522s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1276s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2781s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 715 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 746 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1992s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 775 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1598s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5384s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 862 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2733s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1898s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 940 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1994s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2904s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1022 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2756s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1071 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1106 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1821s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1335s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.2297s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.3262s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1243 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1833s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1729s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 1308 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5505s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2173s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1393 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1432 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1917s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1419s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0515s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2195s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1535 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1576 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1899s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1382s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3589s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1675 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.1392s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1731 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1924s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1458s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.5391s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1830 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (7.2302s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1894 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1940s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1937 out of 1944 | elapsed:  5.4min remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1944 out of 1944 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=3, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'solver': ['adam'], 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'learning_rate': ['constant', 'adaptive'], 'learning_rate_init': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'momentum': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPRegressor(hidden_layer_sizes = (3),\n",
    "                  activation = 'identity',\n",
    "                  max_iter = 500,\n",
    "                  early_stopping = True,\n",
    "                  random_state=42\n",
    "                 )\n",
    "parameters = {\n",
    "    'solver': ['adam'],\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': 10.0 ** -np.arange(1, 7),\n",
    "    'momentum': np.arange(0.1, 1, 0.1), \n",
    "}\n",
    "clf = GridSearchCV(nn, parameters, n_jobs = -1, verbose = 10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8236779361221156\n",
      "Best params: {'alpha': 1e-06, 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'momentum': 0.1, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(clf.best_score_))\n",
    "print(\"Best params: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 47 candidates, totalling 141 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 141 out of 141 | elapsed:   21.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_hyper = MLPRegressor(activation = 'identity',\n",
    "                        max_iter = 500,\n",
    "                        solver='adam',\n",
    "                        alpha=0.00001,\n",
    "                        learning_rate_init=0.01,\n",
    "                        learning_rate='constant',\n",
    "                        early_stopping = True,\n",
    "                        momentum=0.1,\n",
    "                        random_state = 42\n",
    "                       )\n",
    "parameters = {'hidden_layer_sizes': np.arange(3,50) }\n",
    "clf_hyper = GridSearchCV(nn_hyper, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_hyper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2106.332110657818\n",
      "Best score: 0.8256752868132895\n",
      "Best params: {'hidden_layer_sizes': (18, 13)}\n"
     ]
    }
   ],
   "source": [
    "nn_loss = MLPRegressor( hidden_layer_sizes = (18),\n",
    "                        activation = 'identity',\n",
    "                        max_iter = 500,\n",
    "                        solver='adam',\n",
    "                        alpha=0.00001,\n",
    "                        learning_rate_init=0.01,\n",
    "                        learning_rate='constant',\n",
    "                        early_stopping = True,\n",
    "                        momentum=0.1,\n",
    "                        random_state = 42\n",
    "                       ).fit(X_train, y_train)\n",
    "print(\"loss: {}\".format(nn_loss.loss_))\n",
    "print(\"Best score: {}\".format(clf_hyper.best_score_))\n",
    "print(\"Best params: {}\".format(clf_hyper.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1951s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  27 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 8), (18, 9), (18, 10), (18, 11), (18, 12), (18, 13), (18, 14), (18, 15), (18, 16)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'hidden_layer_sizes': [(18,8),(18,9),(18,10),(18,11),(18,12),(18,13),(18,14),(18,15),(18,16)] }\n",
    "clf_hyper = GridSearchCV(nn_hyper, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_hyper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2198.0067503055934\n",
      "Best score: 0.8256752868132895\n",
      "Best params: {'hidden_layer_sizes': (18, 13)}\n"
     ]
    }
   ],
   "source": [
    "nn_loss = MLPRegressor( hidden_layer_sizes = (18,13),\n",
    "                        activation = 'identity',\n",
    "                        max_iter = 500,\n",
    "                        solver='adam',\n",
    "                        alpha=0.00001,\n",
    "                        learning_rate_init=0.01,\n",
    "                        learning_rate='constant',\n",
    "                        early_stopping = True,\n",
    "                        momentum=0.1,\n",
    "                        random_state = 42\n",
    "                       ).fit(X_train, y_train)\n",
    "print(\"loss: {}\".format(nn_loss.loss_))\n",
    "print(\"Best score: {}\".format(clf_hyper.best_score_))\n",
    "print(\"Best params: {}\".format(clf_hyper.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  24 | elapsed:    3.9s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 8), (18, 13, 9), (18, 13, 10), (18, 13, 11), (18, 13, 12), (18, 13, 13), (18, 13, 14), (18, 13, 15)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'hidden_layer_sizes': [(18,13,8),(18,13,9),(18,13,10),(18,13,11),(18,13,12),(18,13,13),(18,13,14),(18,13,15),] }\n",
    "clf_hyper = GridSearchCV(nn_hyper, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_hyper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8249503761838812\n",
      "Best params: {'hidden_layer_sizes': (18, 13, 11)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(clf_hyper.best_score_))\n",
    "print(\"Best params: {}\".format(clf_hyper.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2262.966416082276\n"
     ]
    }
   ],
   "source": [
    "nn_loss = MLPRegressor( hidden_layer_sizes = (18,13,11),\n",
    "                        activation = 'identity',\n",
    "                        max_iter = 500,\n",
    "                        solver='adam',\n",
    "                        alpha=0.00001,\n",
    "                        learning_rate_init=0.01,\n",
    "                        learning_rate='constant',\n",
    "                        early_stopping = True,\n",
    "                        momentum=0.1,\n",
    "                        random_state = 42\n",
    "                       ).fit(X_train, y_train)\n",
    "print(\"loss: {}\".format(nn_loss.loss_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed:    3.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='identity', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=500, momentum=0.1,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'hidden_layer_sizes': [(18, 13, 11, 8), (18, 13, 11, 9), (18, 13, 11, 10), (18, 13, 11, 11), (18, 13, 11, 12), (18, 13, 11, 13), (18, 13, 11, 14), (18, 13, 11, 15), (18, 13, 11, 16), (18, 13, 11, 17), (18, 13, 11, 18), (18, 13, 11, 19)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'hidden_layer_sizes': [(18,13,11,i) for i in range(8,20)] }\n",
    "clf_hyper = GridSearchCV(nn_hyper, parameters, n_jobs = -1, verbose = 10)\n",
    "clf_hyper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8261844992882401\n",
      "Best params: {'hidden_layer_sizes': (18, 13, 11, 12)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(clf_hyper.best_score_))\n",
    "print(\"Best params: {}\".format(clf_hyper.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
